# -*- coding: utf-8 -*-
"""(1.) Credit_Card_Fraud_Detection_with_XGboost_&_Comparision_of_Hyperparameter_tuning_with_GridSearchCV_&_RandomizedSearchCV

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dtICEYqj1C8IdL0dFRk2jZ3JKyfS7HEv

# Mounting the drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""# Importing libraries"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""# Understanding the data and doing Feature Engineering using Pandas"""

df = pd.read_csv('/content/drive/My Drive/My work/Credit card fraud detection/creditcard.csv')

df.head() # to take a quick look dataframe

df.shape # checking shape of the dataframe

df.isnull().sum() # checking total number of null values in all columns

df.describe()

df.nunique() # checking number of unique values in all columns

df.Class[df['Class']==1].count() # there is 492 fraud cases in whole dataset

df.columns # these are the columns in our dataset

# Time, V1 to V9 with Class column
columns_1 = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'Class']

# V10 to V19 with class
columns_2 = ['V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'Class']

# V20 to Amount and CLass
columns_3 = [ 'V20',
       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',
       'Class']

corelation = df[columns_1].corr()
fig, ax = plt.subplots(figsize=(12,12))         # Sample figsize in inches
sns.heatmap(corelation, annot=True, linewidths=.5, ax=ax)

#Time and V3 has corelation of -0.42

corelation = df[columns_2].corr()
fig, ax = plt.subplots(figsize=(12,12))         # Sample figsize in inches
sns.heatmap(corelation, annot=True, linewidths=.5, ax=ax)

# V10 has -0.22, V12 has -0.26, V14 has -0.3, V16 has -0.2, V17 has -0.33 and V18 has -0.11 corelation with Class

corelation = df[columns_3].corr()
fig, ax = plt.subplots(figsize=(12,12))         # Sample figsize in inches
sns.heatmap(corelation, annot=True, linewidths=.5, ax=ax)

# V20 has 0.34 and V21 has 0.11 corelation with Amount

df['V14'].describe()

df['V17'].describe()

"""Visualizing Correlation Matrix of all features"""

df.shape # checking numbers of column for making Correlation Matrix

cols = list(range(31))  # list of all features
fig, ax = plt.subplots(figsize=(30,30)) # defining the size and shape of the plot
corelation = df.iloc[:,cols].corr() 
sns.heatmap(corelation, xticklabels = corelation.columns, yticklabels = corelation.columns, annot = True)
plt.savefig('range all.png') # saving the plot

# check saved file

# we can see that there is very less correlation between main features (V1 to V28) so these are ready to feed in our model

"""## Analysis and Visualization of our problem"""

df.Class.value_counts() # checking the count of values in Class column

df.Class.value_counts().plot(kind='bar', figsize = (10,10), title = 'Bar Graph of 0 and 1 in Class column')
# as we can see that 1 (fraud) is very less than 0 (Not fraud)

# for better representation we can plot these values on logrithmic scale

df.Class.value_counts().plot(kind='bar',  loglog = 'sym', title = 'Logrithmic Bar Graph of 0 and 1 in Class column')

"""Now we clearly see that this data is imbalanced"""

plt.scatter(df.Amount, df.Time, c=df.Class,alpha = 0.5,edgecolor='black',linewidth= 1, label = 'Not Fraud')
plt.scatter(df.Amount, df.Time, marker = 'x', s = 20*df.Class , c = df.Class, label = 'Fraud')
plt.title('Time vs Amount Scatter Plot')
plt.xlabel('Amount')
plt.ylabel('Time')
plt.legend()
plt.show()

df.Amount[df.Class == 1].max()  # maximum amount related to the fraud case is 2125.87 units

fig, ax = plt.subplots(figsize=(10,4))  
plt.scatter(df.Amount, df.Class ,alpha = 0.5,edgecolor='black',linewidth= 1, label = 'Transaction')
plt.axvline(df.Amount[df.Class == 1].max(),linewidth = 2,c = 'red' ,label='Max Amount of Fraud transaction(2125.87)' )
plt.title('Fraud Status vs Amount Scatter Plot')
plt.xlabel('Amount')
plt.ylabel('Fraud Status')
plt.legend()
plt.show()

fig, ax = plt.subplots(figsize=(10,4))  
plt.scatter(df.V22, df.Class ,alpha = 0.5,edgecolor='black',linewidth= 1, label = 'Transaction')

plt.title('V vs Class Plot')
plt.xlabel('V')
plt.ylabel('Fraud Status')
plt.legend()
plt.show()
# V10 has -0.22, V12 has -0.26, V14 has -0.3, V16 has -0.2, V17 has -0.33 and V18 has -0.11 corelation with Class

df.Time[df.Class == 1].describe()

"""# Splitting the Features and Target variables"""

X = df.iloc[:, df.columns != 'Class'].values # Selecting All columns except Class column 
y = df.iloc[:, df.columns == 'Class'].values # Selecting Only Class column

X.shape # shape of X

y.shape # shape of y

"""# Train-Test Split"""

# train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)

X_train.shape # shape of X_train

X_test.shape # shape of X_test

y_train.shape # shape of y_train

y_test.shape # shape of y_test

"""# Default Xgboost Classifier model"""

# Xgboost model
from xgboost import XGBClassifier
classifier = XGBClassifier()

from datetime import datetime

start_time = timer(None) # timing starts from this point for "start_time" variable
classifier.fit(X_train, y_train.ravel())
timer(start_time) # timing ends here for "start_time" variable

# an error is prevented by replacing y_train with y_train.ravel() [it converts that array shape to (n, )]

"""X_test prediction on default hyperparameters"""

from sklearn.metrics import confusion_matrix, accuracy_score
y_pred = classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

print(classification_report(y_test,y_pred))

"""Whole X set prediction on default hyperparameters"""

from sklearn.metrics import confusion_matrix, accuracy_score,f1_score, classification_report
y_pred = classifier.predict(X)
cm = confusion_matrix(y, y_pred)
print(cm)
accuracy_score(y, y_pred)

print(classification_report(y,y_pred))

"""# Hyperparameters tuning with GridSearchCV"""

from sklearn.model_selection import GridSearchCV

params={
 "learning_rate"    : [0.05, 0.3] ,
 "max_depth"        : [  12, 15]
    
}

# for tracking time
def timer(start_time=None):
    if not start_time:
        start_time = datetime.now()
        return start_time
    elif start_time:
        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)
        tmin, tsec = divmod(temp_sec, 60)
        print('\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))

grid_search= GridSearchCV(estimator = classifier,param_grid=params,scoring='f1',n_jobs=-1,cv=5)

from datetime import datetime

start_time = timer(None) # timing starts from this point for "start_time" variable
grid_search.fit(X_train,y_train.ravel())
timer(start_time) # timing ends here for "start_time" variable

grid_search.best_estimator_

grid_search.best_params_

accuracy = grid_search.best_score_
accuracy

grid_tuned_classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0,
              learning_rate=0.3, max_delta_step=0, max_depth=12,
              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
              nthread=None, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
              silent=None, subsample=1, verbosity=1)

"""X_test set prediction"""

grid_tuned_classifier.fit(X_train, y_train.ravel())
y_pred = grid_tuned_classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
print('Accuracy on X_test set ',accuracy_score(y_test, y_pred))

print('Classification report on X_test set\n',classification_report(y_test,y_pred))

"""X set prediction"""

y_pred = grid_tuned_classifier.predict(X)
cm = confusion_matrix(y, y_pred)
print(cm)
print('Accuracy on whole X set ',accuracy_score(y, y_pred))

print('Classification report on whole X set\n',classification_report(y,y_pred))

"""# Hyperparameter tuning with RandomizedSearchCV"""

from sklearn.model_selection import RandomizedSearchCV

params={
 "learning_rate"    : [0.05, 0.1, 0.2, 0.3, 1 ] ,
 "max_depth"        : [10, 12, 15],
 "min_child_weight" : [ 1, 3 ],
 "gamma"            : [ 0.0, 0.15, 0.3]
    
}

# for tracking time
def timer(start_time=None):
    if not start_time:
        start_time = datetime.now()
        return start_time
    elif start_time:
        thour, temp_sec = divmod((datetime.now() - start_time).total_seconds(), 3600)
        tmin, tsec = divmod(temp_sec, 60)
        print('\n Time taken: %i hours %i minutes and %s seconds.' % (thour, tmin, round(tsec, 2)))

random_search= RandomizedSearchCV(estimator = classifier,param_distributions=params,n_iter=10,scoring='f1',n_jobs=-1,cv=5)

from datetime import datetime

start_time = timer(None) # timing starts from this point for "start_time" variable
random_search.fit(X_train,y_train.ravel())
timer(start_time) # timing ends here for "start_time" variable

random_search.best_estimator_

random_search.best_params_

accuracy = random_search.best_score_
accuracy

random_tuned_classifier = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
              colsample_bynode=1, colsample_bytree=1, gamma=0.0,
              learning_rate=0.2, max_delta_step=0, max_depth=10,
              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,
              nthread=None, objective='binary:logistic', random_state=0,
              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
              silent=None, subsample=1, verbosity=1)

"""X_test set prediction"""

random_tuned_classifier.fit(X_train, y_train.ravel())
y_pred = random_tuned_classifier.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
print('Accuracy on X_test set ',accuracy_score(y_test, y_pred))

print('Classification report of X_test set',classification_report(y_test,y_pred))

"""Whole X set prediction"""

y_pred = random_tuned_classifier.predict(X)
cm = confusion_matrix(y, y_pred)
print(cm)
print('Accuracy on whole X set',accuracy_score(y, y_pred))

print('Classification report on whole X set',classification_report(y,y_pred))

"""# Conclusion"""

conclusion = pd.read_csv('Final_conclusion.csv')

conclusion

conclusion.columns

fig, ax = plt.subplots(figsize=(7,7))
plt.plot(conclusion.model,conclusion.xtest_precision, label = 'Precision', marker = 'o')
plt.plot(conclusion.model,conclusion.xtest_f1score, label = 'f1-score', c = 'Black', marker = 'o')
plt.plot(conclusion.model,conclusion.xtest_recall, label = 'Recall', c = 'Red', marker = 'o')
plt.title('Precision / Recall / f1-score Variation on various models of xtest set')
plt.grid()
plt.xlabel('Hyperparameter tuning')
plt.ylabel('out of 1')
plt.legend()
plt.show()

fig, ax = plt.subplots(figsize=(7,7))
plt.plot(conclusion.model,conclusion.x_precision, label = 'Precision', marker = 'o')
plt.plot(conclusion.model,conclusion.x_f1score	, label = 'f1-score', c = 'Black', marker = 'o')
plt.plot(conclusion.model,conclusion.x_recall, label = 'Recall', c = 'Red', marker = 'o')
plt.title('Precision / Recall / f1-score Variation on various models of X set')
plt.grid()
plt.xlabel('Hyperparameter tuning')
plt.ylabel('out of 1')
plt.legend()
plt.show()

fig, ax = plt.subplots(figsize=(7,7))
plt.plot(conclusion.model,conclusion.X_test_accuracy, label = 'X_test Accuracy', marker = 'o')
plt.plot(conclusion.model,conclusion.X_accuracy, label = 'X Accuracy', c = 'Red', marker = 'o')
plt.title('Accuracy Variation on various models of x_test and x set')
plt.grid()
plt.xlabel('Hyperparameter tuning')
plt.ylabel('out of 1')
plt.legend()
plt.show()

fig, ax = plt.subplots(figsize=(7,7))
plt.plot(conclusion.model,conclusion.time_taken, label = 'time in seconds', marker = 'o')
plt.title('Time taken to train various models of on X_train set')
plt.xlabel('Hyperparameter tuning')
plt.ylabel('Time Taken in Seconds')
plt.legend()
plt.grid()
plt.show()

"""Conclusion-


1.   Grid Search CV Hyperparameter tuning gave better results in less time (with 4 parameters' grid). But it takes more time when grid is bigger.
2.   Accuracy, Recall, Precision and f1-score is better for Grid Search CV than Randomized Search SV (with lesser time and lesser grid size of parameters)
3. With the same grid size of parameters, Grid Search CV takes very much time, so this is prohibited for bigger grids.
4. f1-score of 0.88 is achieved by both GridSearchCV and RandomizedSearchCV Hyperparameter tuning on X_test set, But GridSearchCV takes half time in comparison with RandomizedSearchCV and alsoa GridSearchCV took only 4 Hyperparameters' values while RandomizedSearchCV took 13 Hyperparameters' values.
"""